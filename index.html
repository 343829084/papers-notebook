<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-dark.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <title>Papers-notebook by gaocegege</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>Papers-notebook</h1>
        <h2>papers I have read</h2>

        <section id="downloads">
          <a href="https://github.com/gaocegege/papers-notebook/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/gaocegege/papers-notebook/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/gaocegege/papers-notebook" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
        <h1>
<a id="论文笔记" class="anchor" href="#%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>论文笔记</h1>

<p>这个 repo 希望能够记录自己阅读论文的过程，其中的论文一部分来自于上课需要阅读的论文，这部分会比较偏安全和虚拟化。还有一部分论文是自己感兴趣，想去了解的，这部分可能比较偏虚拟化和分布式。论文笔记希望能够记录自己在读论文的时候的想法，其中包括但不限于论文的大致 idea，实现方式，以及自己对论文的评价等等。希望能够把每一篇论文的笔记限制在 1000 字以内。</p>

<h2>
<a id="目录toc" class="anchor" href="#%E7%9B%AE%E5%BD%95toc" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>目录(TOC)</h2>

<ul>
<li>
<a href="#%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0">论文笔记</a>

<ul>
<li><a href="#%E7%9B%AE%E5%BD%95toc">目录(TOC)</a></li>
<li>
<a href="#%E5%88%86%E5%B8%83%E5%BC%8Fdistributed-system">分布式(Distributed System)</a>

<ul>
<li>
<a href="#%E8%B0%83%E5%BA%A6%E5%99%A8scheduler">调度器(Scheduler)</a>

<ul>
<li><a href="#mesos">Mesos</a></li>
<li><a href="#omega">Omega</a></li>
<li><a href="#borg">Borg</a></li>
<li><a href="#yarn">Yarn</a></li>
<li><a href="#sparrow">Sparrow</a></li>
<li><a href="#hawk">Hawk</a></li>
<li><a href="#mercury">Mercury</a></li>
<li><a href="#tarcil">Tarcil</a></li>
</ul>
</li>
<li>
<a href="#lock-service">Lock Service</a>

<ul>
<li><a href="#chubby">Chubby</a></li>
</ul>
</li>
<li>
<a href="#%E4%B8%80%E8%87%B4%E6%80%A7consensus">一致性(Consensus)</a>

<ul>
<li><a href="#raft">Raft</a></li>
<li><a href="#zookeeper">Zookeeper</a></li>
<li><a href="#paxos">Paxos</a></li>
</ul>
</li>
<li>
<a href="#%E5%AD%98%E5%82%A8storage">存储(Storage)</a>

<ul>
<li><a href="#dynamo">Dynamo</a></li>
<li><a href="#spanner">Spanner</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#%E8%99%9A%E6%8B%9F%E5%8C%96virtualization">虚拟化(Virtualization)</a>

<ul>
<li>
<a href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AE%A1%E7%90%86%E5%99%A8hypervisor">虚拟机管理器(Hypervisor)</a>

<ul>
<li><a href="#xen">Xen</a></li>
<li><a href="#kvm">kvm</a></li>
</ul>
</li>
<li>
<a href="#%E5%AE%B9%E5%99%A8container">容器(Container)</a>

<ul>
<li><a href="#mbox">mbox</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#%E6%B2%99%E7%AE%B1sandboxing">沙箱(Sandboxing)</a>

<ul>
<li>
<a href="#%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E6%8B%A6%E6%88%AAsystem-call-interposition">系统调用拦截(System Call Interposition)</a>

<ul>
<li><a href="#janus">Janus</a></li>
<li><a href="#ostia">Ostia</a></li>
</ul>
</li>
<li>
<a href="#%E8%BD%AF%E4%BB%B6%E6%95%85%E9%9A%9C%E9%9A%94%E7%A6%BBsoftware-based-fault-isolation">软件故障隔离(Software-based Fault Isolation)</a>

<ul>
<li><a href="#sfi">SFI</a></li>
<li><a href="#google-native-client">Google Native Client</a></li>
<li><a href="#language-independent-sandboxing">Language-Independent Sandboxing</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#%E7%B3%BB%E7%BB%9Fsystem">系统(System)</a>

<ul>
<li>
<a href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9Ffile-system">文件系统(File System)</a>

<ul>
<li><a href="#optimistic-crash-consistency">Optimistic Crash Consistency</a></li>
</ul>
</li>
<li>
<a href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9Foperating-system">操作系统(Operating System)</a>

<ul>
<li><a href="#exokernel">Exokernel</a></li>
</ul>
</li>
<li>
<a href="#cfi">CFI</a>

<ul>
<li><a href="#control-flow-integrity">Control-Flow Integrity</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#%E5%AE%89%E5%85%A8security">安全(Security)</a>

<ul>
<li>
<a href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E5%85%A8virtulization-security">虚拟机安全(Virtulization, Security)</a>

<ul>
<li><a href="#cloudvisor">CloudVisor</a></li>
</ul>
</li>
<li>
<a href="#taint-tracing">Taint Tracing</a>

<ul>
<li><a href="#taintdroid">TaintDroid</a></li>
</ul>
</li>
<li>
<a href="#rop">ROP</a>

<ul>
<li><a href="#hacking-blind">Hacking Blind</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#%E5%A4%A7%E6%95%B0%E6%8D%AE">大数据</a>

<ul>
<li>
<a href="#%E6%A1%86%E6%9E%B6">框架</a>

<ul>
<li><a href="#hadoop">Hadoop</a></li>
<li><a href="#spark">Spark</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

<p>Created by <a href="https://github.com/ekalinin/github-markdown-toc">gh-md-toc</a></p>

<h2>
<a id="分布式distributed-system" class="anchor" href="#%E5%88%86%E5%B8%83%E5%BC%8Fdistributed-system" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>分布式(Distributed System)</h2>

<h3>
<a id="调度器scheduler" class="anchor" href="#%E8%B0%83%E5%BA%A6%E5%99%A8scheduler" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>调度器(Scheduler)</h3>

<ul>
<li><a href="https://medium.com/@ArmandGrillet/comparison-of-container-schedulers-c427f4f7421">Comparison of Container Schedulers</a></li>
<li><a href="http://www.infoq.com/cn/articles/scheduler-architectures">集群调度框架的架构演进之路</a></li>
</ul>

<p>在我看来，分布式是研究如何让程序能够在多台机器上运行拥有更好的性能的一个方向。那如果要实现这一点，调度很关键。</p>

<p>目前我读过的与分布式调度器有关的论文有 Mesos, Omega, Yarn 和 Borg。这其中 Mesos 是最早的，它来自伯克利大学。其最亮的地方在于两层调度的框架，使得调度跟框架是松耦合的。目前很多公司都是在用它的，而且有很多基于 Mesos 的创业公司，比如 Mesosphere 等等。Omega 跟 Mesos 的第二作者是一个人。Omega 具体来说也不知道算是谁写的，应该算是大学和谷歌一起做的研究。Omega 发表在 EuroSys'13 上，是在基于 Mesos 的基础上，提出了一种完全并行的调度的解决方案，能够在调度上有更好的性能。不过论文是采取的模拟实验来进行验证的，不知道是否有生产上的使用。Borg 是发表在 EuroSys'15 上的，是谷歌真正一直在使用的集群管理工具。可以说谷歌为什么可以用廉价的机器来达到很高的可用性，有很大一部分是因为 Borg。Borg 和 Omega 是不开源的，而 Mesos 是开源的，不过 Borg 有一个开源的继任者，就是目前大名鼎鼎的 Kubernetes。Kubernetes 下面用 Docker Conatainer，而不是 Linux 内核的那些用来做进程级别的性能隔离的特性来实现的。不过最近 Kubernetes 似乎在跟 Docker 撕逼，因为 Docker 公司的一些强势吧，可能之后不会只支持 Docker Conatiner。Kubernetes 在很长的时间内都不是 production ready 的，只能支持 100 个节点，跟 Borg 的 10K 完全没法比，不知道现在是什么情况。</p>

<h4>
<a id="mesos" class="anchor" href="#mesos" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mesos</h4>

<p><a href="https://people.eecs.berkeley.edu/%7Ealig/papers/mesos.pdf">Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center</a></p>

<pre><code>// TODO Add the notes
</code></pre>

<h4>
<a id="omega" class="anchor" href="#omega" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Omega</h4>

<p><a href="http://web.eecs.umich.edu/%7Emosharaf/Readings/Omega.pdf">Omega: flexible, scalable schedulers for large compute clusters</a></p>

<pre><code>// TODO Add the notes
</code></pre>

<h4>
<a id="borg" class="anchor" href="#borg" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Borg</h4>

<p><a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/43438.pdf">Large-scale cluster management at Google with Borg</a></p>

<p>Borg 是谷歌发表在 EuroSys'15 上的一篇文章，讲述了其内部是如何做集群管理的。Borg 是我看过的第一篇关于集群管理的论文。首先介绍下 Borg 的特点，Borg 是一个用来做集群管理的工具，它的目标就是让跑在它上面的应用能够拥有很好的可用性和可靠性的同时，能够提高机器的利用率，而且这些是在一个非常大规模的机器环境下。在 Borg 被设计的时候，还没有对虚拟化的硬件支持，也就是 Intel VT-x 等等那些硬件特性，所以 Borg 是使用了进程级别的隔离手段，也就是 Control Group。</p>

<p>Borg 的架构其实还挺简单的，是比较经典的 Master/Slave 架构，其中在 Master 部分，有两个抽象的进程，一个是 Borg Master，一个是 Borg Scheduler。Borg Master 是有5个备份的，每个都会在内存里维护集群里所有对象的状态。他们5个组成了一个小集群，用 Paxos 算法做一致性的，会选举出一个 leader 来处理请求，这点是之前 Kubernetes 做不到的。</p>

<p>调度器方面的实现比较简单，就是一个队列，根据优先级做 round-robin。这里读起来感觉没什么新意，就不多说了。调度的平均时间大概是 25s，其中 80% 的时间在下载包。谷歌也是实诚，下载安装包的时间都算到调度里面去。</p>

<p>谷歌写的论文一向是简单易懂，特别良心的。所以要是对集群感兴趣，可以去看下这篇论文，花两三个小时就能看完了。</p>

<h4>
<a id="yarn" class="anchor" href="#yarn" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Yarn</h4>

<p><a href="https://www.sics.se/%7Eamir/id2221/papers/2013%20-%20Apache%20Hadoop%20YARN%20-%20Yet%20Another%20Resource%20Negotiator%20(SoCC).pdf">Apache Hadoop YARN: Yet Another Resource Negotiator</a></p>

<pre><code>// TODO Wait to read
</code></pre>

<h4>
<a id="sparrow" class="anchor" href="#sparrow" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sparrow</h4>

<ul>
<li><a href="https://people.eecs.berkeley.edu/%7Ekeo/publications/sosp13-final17.pdf">Sparrow: Distributed, Low Latency Scheduling</a></li>
<li><a href="https://github.com/radlab/sparrow">Sparrow in GitHub</a></li>
</ul>

<p>Sparrow 是一个与前面的调度器架构都不一样的实现，是去中心化的架构。之前的所有调度器，无论是 monolithic 的还是后面 Mesos 那样两层的架构，都是有一个中心化的调度器在运行，这样的方式会使得调度器的效率不是那么高。 Sparrow 是 AMPLab 的又一力作，发表在 SOSP'13 上，它不是一个 general-purpose 的调度器，而是针对 short job 这一特殊的 workload。其灵感来源于一个负载均衡方面的经典论文，k choices。这篇文章的 idea 是，在 k 台机器里选一个最好的，而不是在 n 里选一个最好的，可以大大降低负载均衡的 overhead，同时也对负载的分配跟最优解差不了多少。</p>

<p>Sparrow 核心的思想就是，在分配 task 的时候，随机选择几个 worker，然后选一个最合适的。因为在 Sparrow 的应用场景里，所有的 task 都是很短的，因此只需要考虑任务队列的长度就差不多了。针对多 task 的分配问题，Sparrow 对其进行了批处理来优化，比如 task 为 2 的时候，不是进行两次选择，每次在 k 个 worker 里选择 1 个，而是在 2k 个 worker 里选择 2 个。</p>

<p>这篇论文读起来很轻松，idea 比较简单，但是是跟之前完全不一样的思路。讲道理，其实 idea 很容易想，在读 k choices 的时候就想这样的思想能不能用在调度器上，结果人家早就想到了。</p>

<p>目前 Sparrow 开源在 GitHub 上，但是没听说哪个公司在把它用在生产系统上。它的最大的问题就是 workload 比较单一，只能对 short job 有比较好的效果。</p>

<h4>
<a id="hawk" class="anchor" href="#hawk" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hawk</h4>

<ul>
<li><a href="https://www.usenix.org/system/files/conference/atc15/atc15-paper-delgado.pdf">Hawk: Hybrid Datacenter Scheduling</a></li>
<li><a href="https://project.inria.fr/epfl-Inria/files/2016/02/talk-pameladelgado.pdf">Hawk in USENIX ATC 2015</a></li>
</ul>

<p>有一种寻找 idea 的方法，就是在已有的两种极端的思想中做一个你中有我，我中有你的取舍，所有计算机的问题，都是 trade off 嘛，两种极端肯定是为了不同的追求，然后提出一个折中的方案，往往是一种取巧的想 idea 的方式。类似的例子有 monolithic kernel，micro kernel 和 hybrid kernel。这篇文章也是这样，它是把去中心化和中心化的调度器做了一个混合。之前提到，去中心化的实现只适合 short job 的 workload，Hawk 在调度 long job 的时候会使用中心化的调度器，在调度 short job 的时候会使用去中心化的调度器。</p>

<p>除此之外，Hawk 为了两者能够更好地在一起工作还做了一些微小的工作，比如在一个 worker 做完所有的事情后，会偷别的 worker 的 short job 来做，果然资本主义的 worker 都是积极进取的。</p>

<p>哦对了，这篇文章的验证是使用谷歌开放的自己的 tracing 数据集来做的，这个数据集也是开源的，在 <a href="https://github.com/google/cluster-data">https://github.com/google/cluster-data</a> 可以找到。</p>

<h4>
<a id="mercury" class="anchor" href="#mercury" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mercury</h4>

<ul>
<li><a href="https://www.usenix.org/system/files/conference/atc15/atc15-paper-karanasos.pdf">Mercury: Hybrid Centralized and Distributed Scheduling in Large Shared Clusters
</a></li>
<li><a href="https://www.usenix.org/sites/default/files/conference/protected-files/atc15_slides_karanasos.pdf">Mercury in USENIX ATC 2015</a></li>
</ul>

<pre><code>// TODO Add the notes
</code></pre>

<h4>
<a id="tarcil" class="anchor" href="#tarcil" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Tarcil</h4>

<ul>
<li><a href="http://web.stanford.edu/%7Ecdel/2015.socc.tarcil.pdf">Tarcil: Reconciling Scheduling Speed and Quality in Large Shared Clusters</a></li>
<li><a href="https://web.stanford.edu/group/mast/cgi-bin/drupal/system/files/2014.techreport.tarcil_0.pdf">Tarcil: High Quality and Low Latency Scheduling in Large, Shared Clusters</a></li>
</ul>

<pre><code>// TODO Add the notes
</code></pre>

<h3>
<a id="lock-service" class="anchor" href="#lock-service" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lock Service</h3>

<h4>
<a id="chubby" class="anchor" href="#chubby" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Chubby</h4>

<p><a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//archive/chubby-osdi06.pdf">The Chubby lock service for loosely-coupled distributed systems</a></p>

<pre><code>// TODO Wait to read
</code></pre>

<h3>
<a id="一致性consensus" class="anchor" href="#%E4%B8%80%E8%87%B4%E6%80%A7consensus" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>一致性(Consensus)</h3>

<h4>
<a id="raft" class="anchor" href="#raft" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Raft</h4>

<p><a href="https://raft.github.io/raft.pdf">In Search of an Understandable Consensus Algorithm(Extended Version)</a></p>

<pre><code>// TODO Add the notes
</code></pre>

<h4>
<a id="zookeeper" class="anchor" href="#zookeeper" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Zookeeper</h4>

<p><a href="http://static.cs.brown.edu/courses/csci2270/archives/2012/papers/replication/hunt.pdf">ZooKeeper: Wait-free coordination for Internet-scale systems</a></p>

<pre><code>// TODO Wait to read
</code></pre>

<h4>
<a id="paxos" class="anchor" href="#paxos" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Paxos</h4>

<ul>
<li><a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//archive/paxos_made_live.pdf">Paxos Made Live - An Engineering Perspective</a></li>
<li><a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/lamport-paxos.pdf">The Part-Time Parliament</a></li>
<li><a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf">Paxos Made Simple</a></li>
</ul>

<pre><code>// TODO Wait to read
</code></pre>

<h3>
<a id="存储storage" class="anchor" href="#%E5%AD%98%E5%82%A8storage" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>存储(Storage)</h3>

<h4>
<a id="dynamo" class="anchor" href="#dynamo" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dynamo</h4>

<p><a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf">Dynamo: Amazon’s Highly Available Key-value Store</a></p>

<pre><code>// TODO Wait to read
</code></pre>

<h4>
<a id="spanner" class="anchor" href="#spanner" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spanner</h4>

<p><a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//archive/spanner-osdi2012.pdf">Spanner: Google’s Globally-Distributed Database</a></p>

<pre><code>// TODO Wait to read
</code></pre>

<h2>
<a id="虚拟化virtualization" class="anchor" href="#%E8%99%9A%E6%8B%9F%E5%8C%96virtualization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>虚拟化(Virtualization)</h2>

<h3>
<a id="虚拟机管理器hypervisor" class="anchor" href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AE%A1%E7%90%86%E5%99%A8hypervisor" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>虚拟机管理器(Hypervisor)</h3>

<h4>
<a id="xen" class="anchor" href="#xen" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Xen</h4>

<ul>
<li><a href="http://www.cl.cam.ac.uk/research/srg/netos/papers/2003-xensosp.pdf">Xen and the Art of Virtualization</a></li>
<li><a href="http://gaocegege.com/Blog/csp/xen-kvm">CSP 课堂笔记之 Hypervisor</a></li>
</ul>

<p>Xen 是非常著名的 Hypervisor，它提出了 para-virtualization 的想法。之前实现虚拟机，都是通过 full-virtualization 的方式，但是那个时候的 X86 其实并不能很好地支持 full-virtualization。举个例子，有些指令原本是应该在 VMM 中被执行的，但是有时会因为指令在不同 ring 有不同的表现，因此并不能成功地 trap 到 VMM 中。为了更加优雅地解决这样的问题，Xen 引入了 hypercall，修改了 Guest 的 OS。通过另外的方式来解决这个问题。</p>

<p>虚拟化最主要的资源是 CPU，Memory 和 IO，Xen 对于三者都有一些比较有趣的地方。其中我觉得最有趣的是对于设备的支持，引入了 Domain 0，前后端驱动的设计让人觉得很自然，而且也避免了把驱动放在 VMM 里，会因为驱动 bug 把 VMM 弄崩的可能。</p>

<h4>
<a id="kvm" class="anchor" href="#kvm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>kvm</h4>

<ul>
<li><a href="https://www.kernel.org/doc/ols/2007/ols2007v1-pages-225-230.pdf">kvm: the Linux Virtual Machine Monitor</a></li>
<li><a href="http://gaocegege.com/Blog/csp/xen-kvm">CSP 课堂笔记之 Hypervisor</a></li>
</ul>

<pre><code>// TODO Add the notes
</code></pre>

<h3>
<a id="容器container" class="anchor" href="#%E5%AE%B9%E5%99%A8container" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>容器(Container)</h3>

<h4>
<a id="mbox" class="anchor" href="#mbox" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>mbox</h4>

<ul>
<li><a href="https://people.csail.mit.edu/nickolai/papers/kim-mbox.pdf">Practical and effective sandboxing for non-root users</a></li>
<li><a href="https://github.com/tsgates/mbox">Open source in GitHub</a></li>
</ul>

<pre><code>// TODO Add the notes
</code></pre>

<h2>
<a id="沙箱sandboxing" class="anchor" href="#%E6%B2%99%E7%AE%B1sandboxing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>沙箱(Sandboxing)</h2>

<p><a href="http://www.ijcaonline.org/archives/volume148/number8/borate-2016-ijca-911256.pdf">Sandboxing in Linux: From Smartphone to Cloud</a></p>

<p>沙箱跟容器其实是有点血缘关系的，要做容器肯定要实现隔离，而沙箱就是专门做隔离的。之所以把他们两个分开介绍是因为沙箱本身是一个很复杂的方向，有很多的种类，而容器只是使用了沙箱技术中的某几种。</p>

<p>沙箱技术大致可以被分为两类，其中第一类是基于隔离的沙箱，该类型的沙箱将应用的执行环境从操作系统中隔离出来，形成一个独立的执行环境。第二类是基于规则的沙箱，该类型的沙箱并不是完全关注于对于应用程序的隔离上，而是用规则的方式控制每个应用的权限，基于规则的沙箱之间可以分享操作系统的逻辑资源。</p>

<p>我读的论文主要都是第一类的沙箱，其中主要的技术是 capabilities, system call interposition, software-based fault isolation 等。</p>

<p>上面的链接是一个综述性质的文章，主要阐述了 Linux 平台上可以用来实现沙箱的内核 feature。它对沙箱的定义和功能介绍的比较简单易懂，不妨一读。</p>

<h3>
<a id="系统调用拦截system-call-interposition" class="anchor" href="#%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E6%8B%A6%E6%88%AAsystem-call-interposition" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>系统调用拦截(System Call Interposition)</h3>

<p>System Call Interposition，顾名思义，就是拦截和过滤系统调用的技术。在沙箱的实现过程中，系统调用是一个很关键的部分。如何能够保证应用只能进行被授权的系统调用，是这个方向的研究做的事情。</p>

<h4>
<a id="janus" class="anchor" href="#janus" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Janus</h4>

<ul>
<li><a href="https://www.usenix.org/legacy/publications/library/proceedings/sec96/full_papers/goldberg/goldberg.pdf">A Secure Environment for Untrusted Helper Applications(Confining the Wily Hacker)</a></li>
<li><a href="http://www2.eecs.berkeley.edu/Pubs/TechRpts/1999/CSD-99-1056.pdf">Janus: an Approach for Confinement of Untrusted Applications</a></li>
<li><a href="http://www.isoc.org/isoc/conferences/ndss/03/proceedings/papers/11.pdf">Traps and Pitfalls: Practical Problems in System Call Interposition Based Security Tools</a></li>
</ul>

<p>链接中的第一篇论文是 1996 年发表的，是 system call interposition 方向上最经典的论文，它提出了一个系统，Janus。这个工具可以根据用户定义的 policy 来对应用的请求调用进行过滤，后面的两篇都是后续的关于 Janus 的论文。</p>

<p>在那个时候，互联网很流行，在互联网上获得的内容，可以直接用本地的 helper application 打开。因为内容本身是不可信的，所以这样的一种模式连带着 helper application 也是不可信的，因此 Janus 希望对这样的应用进行限制和隔离，使得应用具有最小的特权，当其被恶意程序攻击后，不会影响整个操作系统。</p>

<p>Janus 的目标有三点，第一个是安全不多说，第二个是灵活，就是要求对系统调用的限制可以达到参数级别，比如 open 在某些参数时可以被调用，其他就不可以，还有就是可配置，允许为不同应用配置不同的策略。</p>

<p>它的实现比较简单，是借助了内核中的 ptrace，然后实现了一个 kernel module 以及一个用户态的 engine。在开始的时候，Janus 会先读取 policy 文件，然后会 fork 子进程，然后父进程会 select 关于子进程的各种事件。子进程会执行 helper app 的逻辑，当有了一个系统调用，会先给 Janus 的内核模块处理，内核模块会跟用户态的 engine 交互，确定请求是不是合法的，合法会交由内核去处理，否则会 deny 掉请求。</p>

<p>下面的两篇论文中提到了一些关于 Janus 的缺点，包括 ptrace 和 Janus 本身的缺点，主要是涉及一些 system call 的监控问题，以及 deny 的方式问题，就不再说了，已经很长了。</p>

<h4>
<a id="ostia" class="anchor" href="#ostia" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ostia</h4>

<p><a href="http://benpfaff.org/papers/ostia.pdf">Ostia: A Delegating Architecture for Secure System Call Interposition</a></p>

<p>Ostia 是在 Janus 等等那一溜论文后面发表的，因此引用了 Janus 中提到的那三篇论文。它最大的贡献，在于提出了一种新的架构，然后解决了之前的基于 filter 的架构不能解决的问题。</p>

<p>它跟 Janus 其实是一挂的工具，都是要在内核态修改一些东西来做的。但是两者的不同在于实现的架构，Janus 是在内核中要有一个负责 tracing 的模块，比如 ptrace。然后在用户态有一个 policy engine，两者会交互，其中是否 deny 请求的逻辑在 policy engine 中，而内核中的模块主要是做 process monitor 的。</p>

<p>Ostia 的实现在我看来参考了虚拟化的一些思想，当一个系统调用到内核的时候，会回调在调用者用户态内存空间中的一个 handler，然后会转发给 agent，然后 agent 会负责校验权限和访问。具体的实现还在看。</p>

<h3>
<a id="软件故障隔离software-based-fault-isolation" class="anchor" href="#%E8%BD%AF%E4%BB%B6%E6%95%85%E9%9A%9C%E9%9A%94%E7%A6%BBsoftware-based-fault-isolation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>软件故障隔离(Software-based Fault Isolation)</h3>

<h4>
<a id="sfi" class="anchor" href="#sfi" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SFI</h4>

<p><a href="https://crypto.stanford.edu/cs155/papers/sfi.pdf">Efficient Software-Based Fault Isolation</a></p>

<p>这篇文章是在 1993 年发表的，也正是这篇文章最早提出了 "sandboxing" 一词。</p>

<pre><code>// TODO Add the notes
</code></pre>

<h4>
<a id="google-native-client" class="anchor" href="#google-native-client" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Google Native Client</h4>

<ul>
<li><a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/34913.pdf">Native Client: A Sandbox for Portable, Untrusted x86 Native Code</a></li>
<li><a href="https://github.com/gaocegege/NaCl-note">论文笔记 in GitHub</a></li>
</ul>

<p>这篇论文是在 CSP 课上读的， 因为需要做分享，所以读的相比于其他论文要仔细一些，之前在阅读的时候就写了一些阅读笔记，比较冗长，这里写一些这篇论文的大概 idea 的介绍，以及一些自己的评论。</p>

<p>Google Native Client(NaCl)，简单来说是一个在浏览器里跑 Native 代码的技术。类比技术是微软<del>臭名昭著</del>的 ActiveX。相比于 ActiveX 那种毫无安全性可言的实现，NaCl 使用了一些自己改良过的 Software Fault Isolation(SFI) 的技术，结合了 ptrace 这样的 System Call Interception 的工具，来实现了在浏览器里安全运行 Native 代码的功能。从实现角度来看，是先对代码进行静态检查，保证代码符合 NaCl 制定的一些规则，然后再把程序运行在一个沙箱内，Native 代码所有跟外界的通讯，包括系统调用，都会被封装或者拦截，使用这样的方式来实现了对 Native 代码的安全隔离。在 2009 年的时候，Google 组织了一个 Native Client Security Contest，鼓励开发者寻找 NaCl 的漏洞，最终发现了 20 多个漏洞但是没有一个可以从根本上破坏 NaCl 的保护。目前 Google Chrome 浏览器仍然支持以这样的方式来运行 Native 代码，只不过好像没有多少人在用的样子。Demo 很容易运行，感兴趣可以试一下，很简单就可以实现从 CPP 代码到 Javascript 代码的通信。</p>

<p>为了提高浏览器段代码运行的效率，还有另外一个流派的做法，那就是 <a href="http://asmjs.org/">asm.js</a>，它的实现思路跟 NaCl 完全不一样，并不会在浏览器里执行 Native 代码，因此不会有这么多安全方面的问题需要考虑，而是通过修改 LLVM 的那一套工具链，把 Native 代码编译成 Javascript 的一个子集，运行这个子集的 Javascript 代码。这样的实现最高可以只比 Native 应用慢一倍，虽然不如 NaCl 媲美原生应用，但是也可以接受了。这是 Firefox 浏览器的路子。</p>

<h4>
<a id="language-independent-sandboxing" class="anchor" href="#language-independent-sandboxing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Language-Independent Sandboxing</h4>

<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.6665&amp;rep=rep1&amp;type=pdf">Language-Independent Sandboxing of Just-In-Time Compilation and Self-Modifying Code</a></p>

<pre><code>// TODO Add the notes
</code></pre>

<h2>
<a id="系统system" class="anchor" href="#%E7%B3%BB%E7%BB%9Fsystem" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>系统(System)</h2>

<h3>
<a id="文件系统file-system" class="anchor" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9Ffile-system" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>文件系统(File System)</h3>

<h4>
<a id="optimistic-crash-consistency" class="anchor" href="#optimistic-crash-consistency" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optimistic Crash Consistency</h4>

<p><a href="http://research.cs.wisc.edu/adsl/Publications/optfs-sosp13.pdf">Optimistic Crash Consistency</a></p>

<p>这是一篇发表在 SOSP'13 上的论文，主要的工作是在 Ext 4 这样的基于 Journal 来做 Crash Recovery 的文件系统的基础上实现了一种 Optimistic 的 Crash Recovery 的方法，这样的方法能够在保证 Crash Consistency 的同时，大幅度提高性能。但是计算机所有的提高都是 tradeoff 的结果，Optimistic Crash Consistency 是牺牲了数据的 Freshness，也就是新鲜度。</p>

<p>Crash Consistency，就是指文件系统在 Crash 之后，其中的数据还是不是一致的。这里的一致指的是 metadata 和 data 等等数据之间的一致。如果不一致的情况发生了，往往意味着硬盘丢了数据，或者文件系统找不到硬盘上的数据。</p>

<p>在基于 Journal 的文件系统中，一次写入磁盘的操作，要写入的数据有 data，以及在 Journal 中的一份 metadata 的冗余，还有 Journal 中的 commit block，以及最后的 metadata。这四个数据要保证写入顺序才能确保 Crash Consistency。因此要保证数据写入的顺序，就要借助磁盘的 flush 操作，来强制地把数据从磁盘的 cache 刷到真正的磁盘中才行。但是这样会导致很大的性能问题，这篇论文提出了使用 checksums，asynchronous durability notifications，delayed writes 等技术来使得文件系统不需要强制的 flush 操作。但是这样的实现，就会牺牲掉数据的 Freshness，在之前 Ext 4 的实现中，Crash 之后最多丢一个 transaction 的数据，现在可能丢 k 个。但是在性能上比带 flush 的 ext 4 提高了 4-10 倍。</p>

<h3>
<a id="操作系统operating-system" class="anchor" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9Foperating-system" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>操作系统(Operating System)</h3>

<h4>
<a id="exokernel" class="anchor" href="#exokernel" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Exokernel</h4>

<p><a href="https://pdos.csail.mit.edu/6.828/2008/readings/engler95exokernel.pdf">Exokernel: An Operating System Architecture for Application-Level Resource Management</a></p>

<pre><code>// TODO Add the notes
</code></pre>

<h3>
<a id="cfi" class="anchor" href="#cfi" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CFI</h3>

<h4>
<a id="control-flow-integrity" class="anchor" href="#control-flow-integrity" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Control-Flow Integrity</h4>

<p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2005/11/ccs05.pdf">Control-Flow Integrity. Principles, Implementations, and Applications</a></p>

<pre><code>// TODO Add the notes
</code></pre>

<h2>
<a id="安全security" class="anchor" href="#%E5%AE%89%E5%85%A8security" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>安全(Security)</h2>

<h3>
<a id="虚拟机安全virtulization-security" class="anchor" href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E5%85%A8virtulization-security" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>虚拟机安全(Virtulization, Security)</h3>

<h4>
<a id="cloudvisor" class="anchor" href="#cloudvisor" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CloudVisor</h4>

<p><a href="https://www.sigops.org/sosp/sosp11/current/2011-Cascais/printable/15-zhang.pdf">CloudVisor: Retrofitting Protection of Virtual Machines in Multi-tenant Cloud with Nested Virtualization</a></p>

<pre><code>// TODO Add the notes
</code></pre>

<h3>
<a id="taint-tracing" class="anchor" href="#taint-tracing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Taint Tracing</h3>

<h4>
<a id="taintdroid" class="anchor" href="#taintdroid" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>TaintDroid</h4>

<ul>
<li><a href="http://www.appanalysis.org/tdroid10.pdf">TaintDroid: An Information-Flow Tracking System for Realtime Privacy Monitoring on Smartphones</a></li>
<li><a href="http://www.appanalysis.org/">Realtime Privacy Monitoring on Smartphones</a></li>
</ul>

<p>Taint 分析，就是指把一些敏感数据标注出来，在程序执行的过程中确保这些被标注的敏感数据不会被泄露出去的技术。TaintDroid 是一个在 Andriod 做 Taint 分析的工具，之前的 Taint 分析工具，overhead 非常大，而 TaintDroid 通过分层的思想，在不同层做不同粒度的 Taint 跟踪，大大降低了运行时的 overhead。</p>

<p>论文有一个配套的 demo，是可以运行的，感兴趣的话可以自己试试看，这里也有一个 <a href="https://www.youtube.com/watch?v=qnLujX1Dw4Y">Demo 视频</a>。很有趣的是这篇论文是 Intel Labs 有参与的，不是很懂他们怎么会想到做这样的事情。</p>

<h3>
<a id="rop" class="anchor" href="#rop" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ROP</h3>

<h4>
<a id="hacking-blind" class="anchor" href="#hacking-blind" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hacking Blind</h4>

<ul>
<li><a href="www.scs.stanford.edu/%7Esorbo/brop/bittau-brop.pdf">Hacking Blind</a></li>
<li><a href="http://ytliu.info/blog/2014/09/28/blind-return-oriented-programming-brop-attack-gong-ji-yuan-li/">【转载】Blind Return Oriented Programming (BROP) Attack - 攻击原理</a></li>
</ul>

<p>这篇论文看上去就很酷，实现很让人亮眼。最简单的 ROP，就是寻找一个个的 gadget，然后把 gadget 连接起来。然后让控制流走到这些 gadget 里，就 OK 了。但是这篇论文是如何在远程来劫持控制流，来实现 ROP 攻击。攻击者不了解远程的系统，因此首先系统要有一个已知的 stack overflow 的漏洞，然后要求攻击的进程在死了后会重启，而且 ASLR 后的地址不变。</p>

<p>其实条件是很苛刻的，而且也不懂为什么一个攻击者可以在不了解远程系统的同时知道系统的 stack overflow 漏洞。整体攻击的过程，是先 Dump 服务器的内存，然后再进行常规的 ROP，其中 Dump 内存的操作非常精巧，感觉只有 ROP 高级玩家才能想出这样的做法，具体可以看看上面链接的论文，是我们学院 IPADS 实验室的一个学长写的，很清楚。</p>

<h2>
<a id="大数据" class="anchor" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>大数据</h2>

<h3>
<a id="框架" class="anchor" href="#%E6%A1%86%E6%9E%B6" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>框架</h3>

<h4>
<a id="hadoop" class="anchor" href="#hadoop" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hadoop</h4>

<ul>
<li><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf">MapReduce: Simplified Data Processing on Large Clusters</a></li>
<li><a href="http://pages.cs.wisc.edu/%7Eakella/CS838/F15/838-CloudPapers/hdfs.pdf">The Hadoop Distributed File System</a></li>
</ul>

<pre><code>// TODO Wait to read
</code></pre>

<h4>
<a id="spark" class="anchor" href="#spark" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spark</h4>

<ul>
<li><a href="https://people.csail.mit.edu/matei/papers/2010/hotcloud_spark.pdf">Spark: Cluster Computing with Working Sets</a></li>
<li><a href="https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</a></li>
</ul>

<pre><code>// TODO Wait to read
</code></pre>
      </section>
    </div>

    
  </body>
</html>
